{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJRaIQGZDmZX"
   },
   "source": [
    "## 머신러닝 성능평가 코드 - 회귀\n",
    "\n",
    "### MAE\n",
    "- 에러의 크기 그대로 반영\n",
    "- 이상치 영향 받음\n",
    "### MSE\n",
    "- 실제값과 예측값 차이의 면적 합\n",
    "- 특이값이 존재하면 수치가 증가\n",
    "### RMSE\n",
    "- 오차에 제곱을 하면 오차가 클수록 그에 따른 가중치가 높게 반영\n",
    "- 이 때, 손실이 기하급수적으로 증가하는 상황에서 실제 오류값의 평균보다 값이 더 커지지 않도록 상쇄하기 위해 사용\n",
    "- 가장 많이 채택하는 성능평가\n",
    "### MSLE\n",
    "- RMSE와 마찬가지로 오차가 기하급수적으로 증가하는 상황에서 실제 오차의 평균보다 값이 더 커지지 않도록 상쇄하기 위해 사용\n",
    "### 결정계수(R^2)\n",
    "- 회귀모형이 선형인 경우 사용\n",
    "- 1에 가까울수록 모형의 설명력이 좋음\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inAcmRBNCpTQ"
   },
   "outputs": [],
   "source": [
    "# 회귀: MAE(Mean Absolute Error)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# 회귀: MSE(Mean Squared Error) and RMSE(Root Mean Squared Error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# 회귀: MSLE(Mean Squared Log Error)\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "\n",
    "# 회귀: 결정계수\n",
    "from skelearn.mtetrics import r2_score\n",
    "r2 =  r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoa88HZkKcm9"
   },
   "source": [
    "## 머신러닝 성능평가 코드 - 분류\n",
    "\n",
    "### 혼동행렬\n",
    "- TP, FP, TN, FN\n",
    "### 정확도\n",
    "- 가장 많이 사용함\n",
    "- 실제 데이터에서 예측 데이터가 얼마나 같은지 판단하는 지표\n",
    "- (TP+TN)/전체\n",
    "### 정밀도\n",
    "- 양성으로 예측한 것 중 실제 양성인 것\n",
    "- TP/(TP+FP)\n",
    "### 재현율, 민감도\n",
    "- 실제로 양성인 것 중 양성이라고 예측한 것\n",
    "- TP/(FN+TP)\n",
    "### F1 스코어\n",
    "- 실제로 양성인 것 중 양성이라고 예측한 것의 비율\n",
    "- 정밀도와 재현율이 어느 한쪽으로 치우쳐지지 않을수록 점수가 높음\n",
    "### ROC 곡선\n",
    "- 이진 분류모델 주요 성능평가지표\n",
    "- false positive rate이 변할 때, true positive rate가 변하는 것을 나타내는 곡선\n",
    "### AUC 스코어\n",
    "- Area under Roc curve\n",
    "- 1에 가까울수록 좋은 모델\n",
    "- 랜덤 수준의 auc값은 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbhUEjO_KncH"
   },
   "outputs": [],
   "source": [
    "# 분류: 혼동행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 분류: 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc =  accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 분류: 정밀도\n",
    "from sklearn.metrics import precision_score\n",
    "pre = precision_score(y_test, y_pred)\n",
    "\n",
    "# 분류: 재현율, 민감도\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# 분류: F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# 분류: Roc curve and AUC 스코어\n",
    "from sklearn.metrics import roc_score, auc\n",
    "import matplolib.pyplot as plt\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred, pos_label = 1)\n",
    "\n",
    "plt.plot(fpr, tpr) # roc curve\n",
    "plt.show()\n",
    "\n",
    "auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdB7gkPNSdkP"
   },
   "source": [
    "## 하이퍼 파라미터 튜닝\n",
    "- 모델 최적화를 위해 여러가지 옵션을 조합하는 방법\n",
    "- Grid Search\n",
    "- Random Search\n",
    "    - 빠른 속도\n",
    "    - 다양한 옵션에 접근이 가능함\n",
    "    - 일반적으로 사용하는 것\n",
    "\n",
    "## 시계열 데이터\n",
    "- 각각 어떤 요인적 특징이 있는지 확인하기\n",
    "- 계절요인: 일정 주기 패턴 반복\n",
    "- 추세요인: 장기적인 시간 동안 특정 경향을 보임\n",
    "- 순환요인: 특정 주기 혹은 수년 간 간격으로 주기적으로 패턴 반복\n",
    "- 불규칙 요인: 예측할 수 없는 이벤트로 우연한 패턴, noise 취급\n",
    "\n",
    "### 시계열: 정상성\n",
    "- 정상성을 가정함\n",
    "- 정상성을 ADF 검정을 통해 검정\n",
    "- 정상성이 없으면 변환작업을 통해서 정상성을 만듦\n",
    "\n",
    "### 시계열 데이터 예측 방법\n",
    "- ARIMA\n",
    "    - sktime 라이브러\n",
    "- LightGBM\n",
    "    - 의사결정트리에 집중한 모델\n",
    "    - 분류 및 다중 분류, 수치 예측 문제에 효과적\n",
    "    - 소규모 데이터셋에서의 과적합\n",
    "- LightGBM 하이퍼파라미터 주요 매개변수\n",
    "    - learing_rate\n",
    "    - n_estimators\n",
    "    - max_depth\n",
    "    - num_leaves\n",
    "    - min_split_gain\n",
    "    - subsample\n",
    "    - random_state\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/3H05o2FGsWSMxHeJ5MDA",
   "collapsed_sections": [
    "lJRaIQGZDmZX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
